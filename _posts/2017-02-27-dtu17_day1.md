---
layout: post
title: Detecting the Unexpected Day one
---

*draft*

Today was the first day of [Detecting the Unexpected](http://www.cvent.com/events/detecting-the-unexpected-discovery-in-the-era-of-astronomically-big-data/event-summary-0db6808d548b4a9ea6466b43046a1ff5.aspx), a conference all about what we don't know about.  How do we find new things in data sets which are too big to look at?  What new tools will we use with the next generation of surveys? As conference chair Josh Peek pointed out, much of this work builds on the big data project of the turn of the last century which led to so much of our current understanding of the Universe.  

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Lovely shoutout to the “founding mothers” of astronomical data science by <a href="https://twitter.com/jegpeek">@jegpeek</a> during the opening remarks of <a href="https://twitter.com/hashtag/dtu17?src=hash">#dtu17</a> <a href="https://twitter.com/hashtag/womenswork?src=hash">#womenswork</a> <a href="https://t.co/BmUVe2iNlN">pic.twitter.com/BmUVe2iNlN</a></p>&mdash; Kelle Cruz (@kellecruz) <a href="https://twitter.com/kellecruz/status/836218996894617601">February 27, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

We had a great set of talks today which started off with Umaa Rebbapragada, who used machine learning to help identify transient objects in the Palomar Plate factor and I though this was a great slide of some of the issues that pop up with dealing with machine learning:   
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Rebbapragada discusses how to overcome training set and domain set having different underlying distributions <a href="https://twitter.com/hashtag/DtU17?src=hash">#DtU17</a> <a href="https://t.co/Jxfjw3CoOi">pic.twitter.com/Jxfjw3CoOi</a></p>&mdash; Molly Peeples (@astronomolly) <a href="https://twitter.com/astronomolly/status/836225313034104832">February 27, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
This was followed by Ashish Mahabah discussing some of the issues that will be further faced by the [LSST](https://www.lsst.org/) survey.   These two topics raised a few points that we would see throughout much of the day:
 * Domain adaptation: Can networks trained on one data set be applicable to another data set?  If not, how much re-training will they require?  
 * Labels, labels, labels:  What training set do you need in order to teach your machines?  


It was a great day filled with so much detail and great talks, and unfortunately I've only mentioend a few highlights and some very broad strokes.   Fortunately, STSCI records the talks and webcasts are availble [here](https://webcast.stsci.edu/webcast/searchresults.xhtml?searchtype=20&eventid=251&sortmode=2). 





