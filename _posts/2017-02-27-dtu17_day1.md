---
layout: post
title: Detecting the Unexpected Day one
---

*draft*

Today was the first day of [Detecting the Unexpected](http://www.cvent.com/events/detecting-the-unexpected-discovery-in-the-era-of-astronomically-big-data/event-summary-0db6808d548b4a9ea6466b43046a1ff5.aspx), a conference all about what we don't know about.  How do we find new things in data sets which are too big to look at?  What new tools will we use with the next generation of surveys? As conference chair Josh Peek pointed out, much of this work builds on the big data project of the turn of the last century which led to so much of our current understanding of the Universe.  

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Lovely shoutout to the “founding mothers” of astronomical data science by <a href="https://twitter.com/jegpeek">@jegpeek</a> during the opening remarks of <a href="https://twitter.com/hashtag/dtu17?src=hash">#dtu17</a> <a href="https://twitter.com/hashtag/womenswork?src=hash">#womenswork</a> <a href="https://t.co/BmUVe2iNlN">pic.twitter.com/BmUVe2iNlN</a></p>&mdash; Kelle Cruz (@kellecruz) <a href="https://twitter.com/kellecruz/status/836218996894617601">February 27, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

We had a great set of talks today which started off with Umaa Rebbapragada, who used machine learning to help identify transient objects in the Palomar Transient factor and I though this was a great slide of some of the issues that pop up with dealing with machine learning:   
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Rebbapragada discusses how to overcome training set and domain set having different underlying distributions <a href="https://twitter.com/hashtag/DtU17?src=hash">#DtU17</a> <a href="https://t.co/Jxfjw3CoOi">pic.twitter.com/Jxfjw3CoOi</a></p>&mdash; Molly Peeples (@astronomolly) <a href="https://twitter.com/astronomolly/status/836225313034104832">February 27, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
This was followed by Ashish Mahabah discussing some of the issues that will be further faced by the [LSST](https://www.lsst.org/) survey and detecting transients in there, and then Casey Law describing the challenges of detecting fast radio bursts. 
  These three talks raised a few points that we would see throughout much of the day:
 * Domain adaptation: Can networks trained on one data set be applicable to another data set?  If not, how much re-training will they require?  
 * Labels, labels, labels:  What training set do you need in order to teach your machines?  
 * Compressing data:  How do we go through the big data streams to what we want to know?
 * Errors:  Why doesn't any ML code include errors? 

The second half of the morning session was focused on deep learning with an overview by Minia Manteiga and then a number of deep learning applications were presented.   Likely because it was the most visual, I found using deep learning to find lensing candidates by Brian Nord and Colin Jacobs to be the most striking, but the most provocative was Marc Huertas-Company and Fernando Caro fitting simulations and comparing them to data.  There was already chatter about an unconference session about that. 

Arjun Dey's talk was highly entertaining and informative about maximizing serendipity discoveries, but his was also one of the first talks to introduce large data sets ready for mining.  Other data sets that are available include Pan Starrs DR1 (Armin Rest and Branimir Sesar) and the Hubble Source Catalog (Rick White).   There is so much data out there, but the big challenge is organizing it in some manner to be useful.   

The afternoon definitely had some great talks on outliers.  This included finding the [400 weirdest spectra in SDSS](http://adsabs.harvard.edu/abs/2017MNRAS.465.4530B) by Dalya Baron and [DEMUD](https://github.com/wkiri/DEMUD) (Discovery via Eigenbasis Modeling of Uninteresting Data) by Kiri Wagstaff.  And a critical point was made by Stephanie Juneau during her talk on AGN and their galaxy hosts, understanding the completeness and systematics are absolutely essential for determine the underlying relationships observed in data. 

It was a great day filled with so much detail that I'm not even coming close to capturing all of the detail nor even what happened during the unconferences! Unfortunately, I've only mentioned a few highlights and some very broad strokes.   Fortunately, STSCI records the talks and webcasts are available [here](https://webcast.stsci.edu/webcast/searchresults.xhtml?searchtype=20&eventid=251&sortmode=2) and there are the [running notes as well](https://docs.google.com/document/d/1RySP1NfCIRntKaKVyvN5XRxkQc-Ue5e3VKEVwc5dEIM/edit#heading=h.lnn2hkgshnh9).

